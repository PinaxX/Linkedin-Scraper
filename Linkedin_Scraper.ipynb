{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Linkedin Scraper.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPY89VhBU19Eb1Cd2hXazOh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PinaxX/Linkedin-Scraper/blob/main/Linkedin_Scraper.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UFD2lr7JhoAN"
      },
      "source": [
        "This notebook can scrape posts from *Linkedin* using user-defined tags. Since there are no official APIs introduced yet, this is the best we can do.\r\n",
        "\r\n",
        "Works fine in 02/28/2021. If *Linkedin* changes URLs or login strategies it'll need modifications.\r\n",
        "\r\n",
        "There are 4 parameters that you need to modify: *username*, *password*, *hashtags* and *SCROLL_PAUSE_TIME*. You can find the first 2 in the second code cell and the other 2 can be found in the third cell.\r\n",
        "\r\n",
        "The scraped data consists of post's text, post's relative date and its author. The last cell will save the data into a CSV file.\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yqWfyAr0ZWvM"
      },
      "source": [
        "# Dependencies:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9O9EDKp0Xz7R"
      },
      "source": [
        "%%capture\r\n",
        "!pip install selenium\r\n",
        "!apt-get update\r\n",
        "!apt install chromium-chromedriver\r\n",
        "!cp /usr/lib/chromium-browser/chromedriver /usr/bin\r\n",
        "\r\n",
        "from selenium import webdriver\r\n",
        "from bs4 import BeautifulSoup\r\n",
        "import pandas as pd\r\n",
        "import time\r\n",
        "import sys\r\n",
        "sys.path.insert(0,'/usr/lib/chromium-browser/chromedriver')\r\n",
        "\r\n",
        "chrome_options = webdriver.ChromeOptions()\r\n",
        "chrome_options.add_argument('--headless')\r\n",
        "chrome_options.add_argument('--no-sandbox')\r\n",
        "chrome_options.add_argument('--disable-dev-shm-usage')\r\n",
        "wd = webdriver.Chrome('chromedriver', options=chrome_options)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YXlMwmT8Zj2p"
      },
      "source": [
        "# Login:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vylA9RZWZE4D"
      },
      "source": [
        "username = 'Your Email'\r\n",
        "password = 'Your Password'\r\n",
        "\r\n",
        "wd.get(\"https://www.linkedin.com/\")\r\n",
        "wd.find_element_by_id(\"session_key\").send_keys(username)\r\n",
        "wd.find_element_by_id(\"session_password\").send_keys(password)\r\n",
        "wd.find_element_by_class_name(\"sign-in-form__submit-button\").click()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ER-NnxEScJsZ"
      },
      "source": [
        "# Scrape:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ViE5y7SjcFv7",
        "outputId": "7f2deac5-a08f-4c22-d07d-143213bf9ade"
      },
      "source": [
        "hashtags = {'machinelearning', 'datascience'}\r\n",
        "SCROLL_PAUSE_TIME = 3\r\n",
        "\r\n",
        "data = []\r\n",
        "\r\n",
        "for hashtag in hashtags:\r\n",
        "  count = 0\r\n",
        "  wd.get(\"https://www.linkedin.com/feed/hashtag/?keywords=\" + hashtag)\r\n",
        "  time.sleep(SCROLL_PAUSE_TIME)\r\n",
        "  last_height = wd.execute_script(\"return document.body.scrollHeight\")\r\n",
        "\r\n",
        "  while True:\r\n",
        "    wd.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\r\n",
        "    time.sleep(SCROLL_PAUSE_TIME)\r\n",
        "    new_height = wd.execute_script(\"return document.body.scrollHeight\")\r\n",
        "    if new_height == last_height:\r\n",
        "      soup = BeautifulSoup(wd.page_source, 'html.parser')\r\n",
        "      break\r\n",
        "    last_height = new_height\r\n",
        "\r\n",
        "  texts = soup.findAll(\"span\", {\"class\": \"break-words\"})\r\n",
        "  names = soup.findAll(\"span\", {\"class\": \"feed-shared-actor__name t-14 t-bold hoverable-link-text t-black\"})\r\n",
        "  dates = soup.findAll(\"span\", {\"class\": \"feed-shared-actor__sub-description t-12 t-normal t-black--light\"})\r\n",
        "  for i in range(len(texts)):\r\n",
        "    texts[i] = BeautifulSoup(str(texts[i]).replace('<br/>', ' <enter> ').replace(',', ' ').replace('\\n', ' <enter> '),\r\n",
        "                             'html.parser').text\r\n",
        "    names[i] = BeautifulSoup(str(names[i]).replace('<br/>', '').replace(',', ' ').replace('\\n', ''), 'html.parser').text\r\n",
        "    dates[i] = BeautifulSoup(str(dates[i]).replace('<br/>', '').replace(',', ' ').replace('\\n', ''), 'html.parser').text\r\n",
        "    dates[i] = dates[i][dates[i].find('  ') + 2:]\r\n",
        "    data.append([hashtag, dates[i], names[i], texts[i]])\r\n",
        "    count += 1\r\n",
        "\r\n",
        "  print(hashtag + ': ' + str(count))\r\n",
        "\r\n",
        "wd.close()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "machinelearning: 533\n",
            "datascience: 473\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hg2bBWYxcj-q"
      },
      "source": [
        "# Save Data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "UNRCNrhkcrUy",
        "outputId": "0fdf3c05-8ed0-4d87-feb8-e655c0a1e82f"
      },
      "source": [
        "df = pd.DataFrame(data, columns=['Hashtag', 'Date', 'Name', 'Text'])\r\n",
        "df.to_csv('data.csv', index=False)\r\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Hashtag</th>\n",
              "      <th>Date</th>\n",
              "      <th>Name</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>machinelearning</td>\n",
              "      <td>35 minutes ago</td>\n",
              "      <td>Vincent Boucher</td>\n",
              "      <td>Investigating the Limitations of the Transfo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>machinelearning</td>\n",
              "      <td>8 minutes ago</td>\n",
              "      <td>Arnav Gupta</td>\n",
              "      <td>Very important thing to understand for those...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>machinelearning</td>\n",
              "      <td>5 days ago</td>\n",
              "      <td>Sabya Dasgupta  Ph.D</td>\n",
              "      <td>If LSTM's were great at predicting BTC price...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>machinelearning</td>\n",
              "      <td>18 minutes ago</td>\n",
              "      <td>Maz'ar Ul Haq</td>\n",
              "      <td>The Future Dogmas That Will Challenge The Fi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>machinelearning</td>\n",
              "      <td>1 day ago</td>\n",
              "      <td>Hashem Al-Ghaili</td>\n",
              "      <td>‘Deep Nostalgia’ uses AI to turn Old Photos ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           Hashtag  ...                                               Text\n",
              "0  machinelearning  ...    Investigating the Limitations of the Transfo...\n",
              "1  machinelearning  ...    Very important thing to understand for those...\n",
              "2  machinelearning  ...    If LSTM's were great at predicting BTC price...\n",
              "3  machinelearning  ...    The Future Dogmas That Will Challenge The Fi...\n",
              "4  machinelearning  ...    ‘Deep Nostalgia’ uses AI to turn Old Photos ...\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    }
  ]
}